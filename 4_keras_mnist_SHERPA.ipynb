{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_mlp.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/peterjsadowski/keras_tutorial/blob/master/4_keras_mnist_SHERPA.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q1pD2rGo0TGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        },
        "outputId": "57e6856b-2c97-4da2-8cc3-7262526f4d00"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SHERPA is a Python library for hyperparameter tuning of machine learning models.\n",
        "Copyright (C) 2018  Lars Hertel, Peter Sadowski, and Julian Collado.\n",
        "\n",
        "This file is part of SHERPA.\n",
        "\n",
        "SHERPA is free software: you can redistribute it and/or modify\n",
        "it under the terms of the GNU General Public License as published by\n",
        "the Free Software Foundation, either version 3 of the License, or\n",
        "(at your option) any later version.\n",
        "\n",
        "SHERPA is distributed in the hope that it will be useful,\n",
        "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
        "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
        "GNU General Public License for more details.\n",
        "\n",
        "You should have received a copy of the GNU General Public License\n",
        "along with SHERPA.  If not, see <http://www.gnu.org/licenses/>.\n",
        "\n",
        "INSTALLATION: \n",
        "pip install parameter-sherpa\n",
        "pip install flask==0.12.2 # Newer version of flash leads to error: 'io.UnsupportedOperation: not writable'\n",
        "\"\"\"\n",
        "!pip install parameter-sherpa\n",
        "!pip install flask==0.12.2\n",
        "\n",
        "from __future__ import print_function\n",
        "import sherpa\n",
        "import time\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting parameter-sherpa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/25/a13f4d1c51d2810f28384b6d5fa277046cd756471f60682c55e9641b310a/parameter_sherpa-0.0.4-py2.py3-none-any.whl (531kB)\n",
            "\u001b[K    100% |████████████████████████████████| 532kB 5.7MB/s \n",
            "\u001b[?25hCollecting pymongo (from parameter-sherpa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/88/dd1f8c4281a60791b043f55e338d0521049208f21e3de19ddc9c160dbbef/pymongo-3.7.1-cp36-cp36m-manylinux1_x86_64.whl (405kB)\n",
            "\u001b[K    100% |████████████████████████████████| 409kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from parameter-sherpa) (0.22.0)\n",
            "Requirement already satisfied: numpy> in /usr/local/lib/python3.6/dist-packages (from parameter-sherpa) (1.14.6)\n",
            "Collecting enum34 (from parameter-sherpa)\n",
            "  Downloading https://files.pythonhosted.org/packages/af/42/cb9355df32c69b553e72a2e28daee25d1611d2c0d9c272aa1d34204205b2/enum34-1.1.6-py3-none-any.whl\n",
            "Collecting flask (from parameter-sherpa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from parameter-sherpa) (0.19.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from parameter-sherpa) (0.19.1)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->parameter-sherpa) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->parameter-sherpa) (2018.5)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from flask->parameter-sherpa) (0.14.1)\n",
            "Collecting itsdangerous>=0.24 (from flask->parameter-sherpa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/b4/a60bcdba945c00f6d608d8975131ab3f25b22f2bcfe1dab221165194b2d4/itsdangerous-0.24.tar.gz (46kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 13.9MB/s \n",
            "\u001b[?25hCollecting click>=5.1 (from flask->parameter-sherpa)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
            "\u001b[K    100% |████████████████████████████████| 81kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from flask->parameter-sherpa) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas->parameter-sherpa) (1.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->flask->parameter-sherpa) (1.0)\n",
            "Building wheels for collected packages: itsdangerous\n",
            "  Running setup.py bdist_wheel for itsdangerous ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/2c/4a/61/5599631c1554768c6290b08c02c72d7317910374ca602ff1e5\n",
            "Successfully built itsdangerous\n",
            "Installing collected packages: pymongo, enum34, itsdangerous, click, flask, parameter-sherpa\n",
            "Successfully installed click-7.0 enum34-1.1.6 flask-1.0.2 itsdangerous-0.24 parameter-sherpa-0.0.4 pymongo-3.7.1\n",
            "Collecting flask==0.12.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/32/e3597cb19ffffe724ad4bf0beca4153419918e7fa4ba6a34b04ee4da3371/Flask-0.12.2-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K    100% |████████████████████████████████| 92kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (2.10)\n",
            "Requirement already satisfied: Werkzeug>=0.7 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (0.14.1)\n",
            "Requirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (0.24)\n",
            "Requirement already satisfied: click>=2.0 in /usr/local/lib/python3.6/dist-packages (from flask==0.12.2) (7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.4->flask==0.12.2) (1.0)\n",
            "Installing collected packages: flask\n",
            "  Found existing installation: Flask 1.0.2\n",
            "    Uninstalling Flask-1.0.2:\n",
            "      Successfully uninstalled Flask-1.0.2\n",
            "Successfully installed flask-0.12.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V-LbMKAn0TG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "6441117b-04e5-4e67-9e79-25bfdf8700c2"
      },
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "num_classes = 10\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qkPRb0Ku0TG_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "parameters = [sherpa.Discrete('num_units', [16, 32])]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpbYAzUL0THE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "algorithm = sherpa.algorithms.BayesianOptimization(max_num_trials=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zS2eyBz70THI",
        "colab_type": "code",
        "colab": {},
        "outputId": "74ee99db-7761-49ee-e4bc-b49b638d28a2"
      },
      "cell_type": "code",
      "source": [
        "study = sherpa.Study(parameters=parameters,\n",
        "                     algorithm=algorithm,\n",
        "                     lower_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:sherpa.core:\n",
            "-------------------------------------------------------\n",
            "SHERPA Dashboard running on http://127.0.1.1:8880\n",
            "-------------------------------------------------------\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "3qJGHSN40THM",
        "colab_type": "code",
        "colab": {},
        "outputId": "9fb1a229-f8d5-4362-dabb-2fe70b96800e"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "for trial in study:\n",
        "    print(\"Trial {}:\\t{}\".format(trial.id, trial.parameters))\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=trial.parameters['num_units'], activation='relu', input_dim=784))\n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              callbacks=[study.keras_callback(trial, objective_name='val_loss')],\n",
        "              validation_data=(x_test, y_test))\n",
        "\n",
        "    study.finalize(trial=trial)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 1:\t{'num_units': 64}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.3021 - acc: 0.9155 - val_loss: 0.1648 - val_acc: 0.9521\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.1451 - acc: 0.9576 - val_loss: 0.1268 - val_acc: 0.9630\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.1062 - acc: 0.9697 - val_loss: 0.1138 - val_acc: 0.9649\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0845 - acc: 0.9750 - val_loss: 0.0997 - val_acc: 0.9682\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0688 - acc: 0.9786 - val_loss: 0.0896 - val_acc: 0.9736\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0569 - acc: 0.9825 - val_loss: 0.0865 - val_acc: 0.9736\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0486 - acc: 0.9850 - val_loss: 0.0857 - val_acc: 0.9741\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0419 - acc: 0.9872 - val_loss: 0.0961 - val_acc: 0.9718\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.0349 - acc: 0.9893 - val_loss: 0.0834 - val_acc: 0.9755\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0998 - val_acc: 0.9710\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.0275 - acc: 0.9914 - val_loss: 0.0991 - val_acc: 0.9741\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0935 - val_acc: 0.9744\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 4s 71us/step - loss: 0.0204 - acc: 0.9939 - val_loss: 0.1027 - val_acc: 0.9725\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 4s 70us/step - loss: 0.0180 - acc: 0.9948 - val_loss: 0.0979 - val_acc: 0.9736\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 4s 72us/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0994 - val_acc: 0.9742\n",
            "Trial 2:\t{'num_units': 96}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.2724 - acc: 0.9227 - val_loss: 0.1453 - val_acc: 0.9578\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.1241 - acc: 0.9638 - val_loss: 0.1089 - val_acc: 0.9675\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0866 - acc: 0.9738 - val_loss: 0.0891 - val_acc: 0.9737\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 5s 85us/step - loss: 0.0661 - acc: 0.9795 - val_loss: 0.0825 - val_acc: 0.9741\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 5s 91us/step - loss: 0.0527 - acc: 0.9837 - val_loss: 0.0806 - val_acc: 0.9736\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0432 - acc: 0.9867 - val_loss: 0.0797 - val_acc: 0.9763\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0360 - acc: 0.9891 - val_loss: 0.0768 - val_acc: 0.9765\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0287 - acc: 0.9912 - val_loss: 0.0803 - val_acc: 0.9757\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0243 - acc: 0.9925 - val_loss: 0.0853 - val_acc: 0.9747\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 6s 92us/step - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0782 - val_acc: 0.9759\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 5s 86us/step - loss: 0.0174 - acc: 0.9948 - val_loss: 0.0877 - val_acc: 0.9749\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 5s 87us/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0835 - val_acc: 0.9764\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 5s 90us/step - loss: 0.0133 - acc: 0.9963 - val_loss: 0.0925 - val_acc: 0.9761\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 5s 88us/step - loss: 0.0116 - acc: 0.9963 - val_loss: 0.0975 - val_acc: 0.9761\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0097 - acc: 0.9971 - val_loss: 0.1002 - val_acc: 0.9744\n",
            "Trial 3:\t{'num_units': 128}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.2605 - acc: 0.9257 - val_loss: 0.1381 - val_acc: 0.9595\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.1152 - acc: 0.9657 - val_loss: 0.1066 - val_acc: 0.9664\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0777 - acc: 0.9771 - val_loss: 0.0859 - val_acc: 0.9746\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0594 - acc: 0.9818 - val_loss: 0.0843 - val_acc: 0.9744\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0451 - acc: 0.9857 - val_loss: 0.0752 - val_acc: 0.9770\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0353 - acc: 0.9890 - val_loss: 0.0801 - val_acc: 0.9771\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0288 - acc: 0.9908 - val_loss: 0.0796 - val_acc: 0.9763\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0233 - acc: 0.9925 - val_loss: 0.0798 - val_acc: 0.9782\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0200 - acc: 0.9937 - val_loss: 0.0811 - val_acc: 0.9774\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0151 - acc: 0.9954 - val_loss: 0.0908 - val_acc: 0.9759\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0143 - acc: 0.9955 - val_loss: 0.0889 - val_acc: 0.9774\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0117 - acc: 0.9965 - val_loss: 0.0937 - val_acc: 0.9777\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0964 - val_acc: 0.9761\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 7s 110us/step - loss: 0.0077 - acc: 0.9976 - val_loss: 0.0936 - val_acc: 0.9775\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 8s 125us/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0985 - val_acc: 0.9763\n",
            "Trial 4:\t{'num_units': 32}\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.3574 - acc: 0.9011 - val_loss: 0.2048 - val_acc: 0.9436\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 4s 61us/step - loss: 0.1860 - acc: 0.9464 - val_loss: 0.1615 - val_acc: 0.9532\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 3s 58us/step - loss: 0.1448 - acc: 0.9574 - val_loss: 0.1447 - val_acc: 0.9566\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1227 - acc: 0.9635 - val_loss: 0.1312 - val_acc: 0.9591\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.1075 - acc: 0.9679 - val_loss: 0.1147 - val_acc: 0.9647\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0975 - acc: 0.9704 - val_loss: 0.1154 - val_acc: 0.9646\n",
            "Epoch 7/15\n",
            "13088/60000 [=====>........................] - ETA: 3s - loss: 0.0900 - acc: 0.9734"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "PYKb3ovt0THQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "8ba7da2b-2897-4dc5-deee-164737994915"
      },
      "cell_type": "code",
      "source": [
        "print(study.get_best_result())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Trial-ID': 9, 'Iteration': 5, 'num_units': 125, 'Objective': 0.06545425380312372}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}